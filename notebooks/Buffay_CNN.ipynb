{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mps_device = torch.device(\"mps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  1.6438e+01,  1.7235e-01,  ...,  8.4722e-01,\n",
       "          3.7038e-01,  0.0000e+00],\n",
       "        [ 1.0000e+00,  1.5357e+01, -1.3720e-02,  ...,  4.4933e-01,\n",
       "          9.7484e-01,  0.0000e+00],\n",
       "        [ 2.0000e+00,  2.3816e+01,  3.3310e-02,  ...,  6.9567e-01,\n",
       "          5.5630e-02,  0.0000e+00],\n",
       "        ...,\n",
       "        [ 7.9970e+03,  2.5299e-01, -5.2870e-02,  ...,  1.0171e-01,\n",
       "          3.5698e-01,  6.4487e-01],\n",
       "        [ 7.9980e+03,  1.7949e+01,  4.4880e-02,  ...,  7.5792e-01,\n",
       "          3.3626e-01,  2.4872e-01],\n",
       "        [ 7.9990e+03,  3.6270e+00, -1.4630e-01,  ...,  7.9199e-01,\n",
       "          7.8141e-01,  1.2063e-01]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.array(pd.read_csv('/Users/neisner/Documents/code/PhoebeBuffay/data/training/theta.txt', delimiter=',')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "   mps_device = torch.device(\"mps\")\n",
    "   x = torch.ones(1, device=mps_device)\n",
    "   print (x)\n",
    "else:\n",
    "   print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the data ready\n",
    "\n",
    "# batch_size = 64\n",
    "# val_cut = 997\n",
    "# df = pd.read_csv('/Users/neisner/Documents/code/PhoebeBuffay/data/training/theta.txt', delimiter=',')\n",
    "# mtx = np.array(df)\n",
    "# T = torch.tensor(mtx, dtype=torch.float64)\n",
    "# training_data = torch.utils.data.TensorDataset(T)\n",
    "\n",
    "# print(np.shape(training_data))\n",
    "\n",
    "# # training_data = torch.utils.data.TensorDataset(torch.tensor(np.zeros((100,19))), torch.tensor(np.zeros((100,500))))\n",
    "# training_generator = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# # validation_data = torch.utils.data.TensorDataset(torch.tensor(np.zeros((20,19))), torch.tensor(np.zeros((20,500))))\n",
    "# # validation_data = torch.utils.data.TensorDataset(torch.tensor(np.load('/Users/neisner/Documents/code/PhoebeBuffay/data/training/theta.txt'), dtype=torch.float32, allow_pickle=True), torch.tensor(np.load('/Users/neisner/Documents/code/PhoebeBuffay/data/training/simulations.npy'), dtype=torch.float32, allow_pickle=True))\n",
    "\n",
    "# validation_generator = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data ready\n",
    "\n",
    "batch_size = 64\n",
    "val_cut = 997\n",
    "cut = 6000\n",
    "\n",
    "data = torch.tensor(np.array(pd.read_csv('/Users/neisner/Documents/code/PhoebeBuffay/data/training/theta.txt', delimiter=',', usecols = range(1,17))))\n",
    "label = torch.tensor(np.array(pd.read_csv('/Users/neisner/Documents/code/PhoebeBuffay/data/training/simulations.txt', delimiter=',', usecols = range(1,501))))\n",
    "\n",
    "training_data = torch.utils.data.TensorDataset(data[0:cut], label[0:cut])\n",
    "\n",
    "# training_data = torch.utils.data.TensorDataset(torch.tensor(np.zeros((100,19))), torch.tensor(np.zeros((100,500))))\n",
    "\n",
    "training_generator = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validation_data = torch.utils.data.TensorDataset(data[cut:-1], label[cut:-1])\n",
    "\n",
    "# validation_data = torch.utils.data.TensorDataset(torch.tensor(np.load('/Users/neisner/Documents/code/PhoebeBuffay/data/training/theta.txt'), dtype=torch.float32, allow_pickle=True), torch.tensor(np.load('/Users/neisner/Documents/code/PhoebeBuffay/data/training/simulations.npy'), dtype=torch.float32, allow_pickle=True))\n",
    "\n",
    "validation_generator = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffayCNN(\n",
      "  (linear1): Linear(in_features=16, out_features=500, bias=True)\n",
      "  (linear2): Linear(in_features=500, out_features=780, bias=True)\n",
      "  (linear3): Linear(in_features=780, out_features=4000, bias=True)\n",
      "  (conv1): Conv1d(1, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(20, 100, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (maxpool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(100, 150, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv4): Conv1d(150, 100, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (maxpool4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv5): Conv1d(100, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv6): Conv1d(20, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (maxpool6): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class buffayCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(buffayCNN, self).__init__()\n",
    "        self.linear1 = nn.Linear(16, 500)\n",
    "        self.linear2 = nn.Linear(500, 780)\n",
    "        self.linear3 = nn.Linear(780, 4000)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(1, 20, kernel_size=3, stride=1, padding=1)\n",
    "        #self.maxpool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(20,100, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool1d(2)\n",
    "        self.conv3 = nn.Conv1d(100, 150, kernel_size=3, stride=1, padding=1)\n",
    "        #self.maxpool3 = nn.MaxPool1d(2)\n",
    "        self.conv4 = nn.Conv1d(150, 100, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool4 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv5 = nn.Conv1d(100, 20, kernel_size=3, stride=1, padding=1)\n",
    "        #self.maxpool5 = nn.MaxPool1d(2)\n",
    "        self.conv6 = nn.Conv1d(20, 1, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool6 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.relu(self.linear3(x))\n",
    "\n",
    "        x = self.relu((self.conv1(x.reshape((x.shape[0], 1, x.shape[1])))))\n",
    "        # x = self.maxpool1(x)\n",
    "        \n",
    "        x = self.relu((self.conv2(x)))\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = self.relu((self.conv3(x)))\n",
    "        # x = self.maxpool3(x)\n",
    "        \n",
    "        x = self.relu((self.conv4(x)))\n",
    "        x = self.maxpool4(x)\n",
    "        \n",
    "        x = self.relu((self.conv5(x)))\n",
    "        # x = self.maxpool5(x)\n",
    "        \n",
    "        x = self.relu((self.conv6(x)))\n",
    "        x = self.maxpool6(x)\n",
    "        \n",
    "                \n",
    "        return x.squeeze()\n",
    "\n",
    "# Create an instance of the SimpleCNN model\n",
    "model = buffayCNN()\n",
    "model.to(mps_device)\n",
    "\n",
    "# model.cuda() # move to the GPU \n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(torch.zeros((10,16))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dierectroy to save the model\n",
    "\n",
    "training_index = 1\n",
    "\n",
    "os.makedirs(f'./model_{training_index}', exist_ok=True)\n",
    "checkpoint_path = f'./model_{training_index}/checkpoint.pth'\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/neisner/Documents/code/PhoebeBuffay/Buffay_CNN.ipynb Cell 12\u001b[0m line \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/neisner/Documents/code/PhoebeBuffay/Buffay_CNN.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/neisner/Documents/code/PhoebeBuffay/Buffay_CNN.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/neisner/Documents/code/PhoebeBuffay/Buffay_CNN.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m y_hat \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/neisner/Documents/code/PhoebeBuffay/Buffay_CNN.ipynb#W5sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Compute the loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/neisner/Documents/code/PhoebeBuffay/Buffay_CNN.ipynb#W5sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(y_hat, y)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/exoplanet/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/exoplanet/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/neisner/Documents/code/PhoebeBuffay/Buffay_CNN.ipynb Cell 12\u001b[0m line \u001b[0;36mbuffayCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/neisner/Documents/code/PhoebeBuffay/Buffay_CNN.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/neisner/Documents/code/PhoebeBuffay/Buffay_CNN.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear1(x))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/neisner/Documents/code/PhoebeBuffay/Buffay_CNN.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear2(x))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/neisner/Documents/code/PhoebeBuffay/Buffay_CNN.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear3(x))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/exoplanet/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/exoplanet/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/exoplanet/lib/python3.9/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 1\n",
    "\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "\n",
    "best_val_loss = np.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    temp_train_losses = []\n",
    "    \n",
    "    for i, (x, y) in enumerate(training_generator):\n",
    "        \n",
    "        \n",
    "        x = x.to(torch.float32)\n",
    "        y = y.to(torch.float32)\n",
    "\n",
    "        x, y = x = x.to(mps_device), y.to(mps_device)\n",
    "        \n",
    "        # x,y = x.cuda(), y.cuda() # move it to the GPU\n",
    "        \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        # Forward pass\n",
    "        y_hat = model(x)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        temp_train_losses.append(loss.item())\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_losses.append(np.mean(np.array(temp_train_losses)))\n",
    "    \n",
    "    temp_val_losses = []\n",
    "    \n",
    "    for i, (x, y) in enumerate(validation_generator):\n",
    "        x = x.to(torch.float32)\n",
    "        y = y.to(torch.float32)\n",
    "        \n",
    "        x, y = x = x.to(mps_device), y.to(mps_device)\n",
    "        \n",
    "        # x,y = x.cuda(), y.cuda()\n",
    "        \n",
    "        model.eval() \n",
    "        \n",
    "        # Forward pass\n",
    "        y_hat_val = model(x)\n",
    "        \n",
    "        # Compute the loss\n",
    "        val_loss = loss_fn(y_hat_val, y)\n",
    "        \n",
    "        temp_val_losses.append(val_loss.item())\n",
    "            \n",
    "    val_losses.append(np.mean(np.array(temp_val_losses)))\n",
    "    \n",
    "    if np.mean(np.array(temp_val_losses)) < best_val_loss:\n",
    "        best_val_loss = np.mean(np.array(temp_val_losses))\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "    \n",
    "    # Print the loss every 100 iterations\n",
    "    if i % 100 == 0:\n",
    "        print(f'Epoch {_}, Iteration {i}, loss: {loss.item()}')\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17f828ac0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.linspace(0,3,len(train_losses)),train_losses,\"x\", label='Training loss')\n",
    "plt.plot(np.linspace(0,3,len(train_losses)), val_losses, \"x\",label='Validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exoplanet",
   "language": "python",
   "name": "exoplanet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
